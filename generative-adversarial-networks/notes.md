# Generative adversarial networks

## Activations functions
- Sigmoid: Values between 0 and 1, working with probability.
- Sigmoid softmax: Value between 0 and 1, wirking with classification.
- ReLU: Values between 0 and infinite, working with multiclasses, like a binary classfication.
- 

## Layers
- All neural network (NN) has a least one layer, without exceptions. It is the input.
- All NN has another layer for the ouput.
- Type of layers:
    - Full connected
    - 
